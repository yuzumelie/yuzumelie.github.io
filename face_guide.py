import cv2
import mediapipe as mp
import numpy as np
import pygame
import time
from PIL import ImageFont, ImageDraw, Image
import os

# ==========================
# 0. ê²½ë¡œ ì„¤ì • (ì—¬ê¸°ë§Œ ìˆ˜ì •!)
# ==========================

AUDIO_FOLDER = r"/Users/millie/Documents/audio"  # mp3ê°€ ìˆëŠ” í´ë” ì ˆëŒ€ ê²½ë¡œë¡œ ìˆ˜ì •
FONT_PATH = r"/System/Library/Fonts/AppleSDGothicNeo.ttc"  # macOS ê¸°ë³¸ í•œê¸€ í°íŠ¸ ê²½ë¡œ

# ==========================
# 1. ì˜¤ë””ì˜¤ ì´ˆê¸°í™”
# ==========================

pygame.mixer.init()

guide_states = ["move_back", "come_in"]
sounds = {}

for state in guide_states:
    path = os.path.join(AUDIO_FOLDER, f"{state}.mp3")
    if os.path.exists(path):
        sounds[state] = pygame.mixer.Sound(path)
        print(f"[Loaded] {path}")
    else:
        print(f"[Missing] {path}")

last_audio_play_time = 0
current_state = None

def play_guide(state, cooldown=2.0):
    """
    ìŒì„± ì¬ìƒ ê·œì¹™:
    - perfectëŠ” ì¬ìƒ ì•ˆ í•¨
    - come_in, move_back ì¤‘ í•˜ë‚˜ê°€ ì¬ìƒë˜ë©´
      ê·¸ í›„ 2ì´ˆ ë™ì•ˆ ë‹¤ë¥¸ ìŒì„±ì€ ì¬ìƒë˜ì§€ ì•ŠìŒ
    - ë‹¨, ê°™ì€ ìŒì„±ì€ cooldown ì•ˆì—ì„œë§Œ ì°¨ë‹¨
    """

    global last_audio_play_time, current_state

    if state == "perfect":
        current_state = state
        return

    now = time.time()
    time_since_last = now - last_audio_play_time

    # -----------------------------
    # 1) ì´ì „ ìŒì„±ê³¼ ë‹¤ë¥¸ ìŒì„±ì¸ë°,
    #    ë§ˆì§€ë§‰ ì¬ìƒ ì´í›„ 2ì´ˆê°€ ì•ˆ ì§€ë‚¬ìœ¼ë©´ ì°¨ë‹¨
    # -----------------------------
    if current_state is not None and current_state != state:
        if time_since_last < 2.0:
            return  # ë‹¤ë¥¸ ìŒì„±ì„ ì°¨ë‹¨

    # -----------------------------
    # 2) ë™ì¼ ìŒì„± ì¬ìƒ ì¿¨ë‹¤ìš´
    # -----------------------------
    if current_state == state and time_since_last < cooldown:
        return

    # -----------------------------
    # 3) ì¬ìƒ
    # -----------------------------
    if state in sounds:
        sounds[state].play()
        print("[AUDIO]", state)

    current_state = state
    last_audio_play_time = now





# ==========================
# 2. í…ìŠ¤íŠ¸ ì¶œë ¥
# ==========================

try:
    font = ImageFont.truetype(FONT_PATH, 24)
    USE_PIL_TEXT = True
except:
    USE_PIL_TEXT = False
    font = None

def draw_text(frame, text, is_good=False):
    h, w, _ = frame.shape
    color = (0, 255, 0) if is_good else (255, 255, 255)

    cv2.rectangle(frame, (0, 0), (w, 40), (0, 0, 0), -1)

    if USE_PIL_TEXT:
        pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil)
        draw.text((10, 5), text, font=font, fill=color)
        frame[:] = cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)
    else:
        cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

# ==========================
# 3. ì–¼êµ´ ë¶„ì„ ë¡œì§
# ==========================

mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(
    max_num_faces=5,
    refine_landmarks=True,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)
def facial_features_visible(face, h, w):
    # ì£¼ìš” ì´ëª©êµ¬ë¹„ landmark
    nose_id = 1
    left_eye_id = 33
    right_eye_id = 263
    mouth_id = 13

    key_ids = [nose_id, left_eye_id, right_eye_id, mouth_id]

    for idx in key_ids:
        lm = face.landmark[idx]

        # landmarkê°€ í”„ë ˆì„ ë°–ì´ë©´ False
        if lm.x < 0 or lm.x > 1 or lm.y < 0 or lm.y > 1:
            return False
    
    return True
def analyze_faces(multi_face_landmarks, w, h):

    if not multi_face_landmarks:
        return "í™”ë©´ ì•ˆìœ¼ë¡œ ë“¤ì–´ì˜¤ì„¸ìš”", "come_in", False

    face = multi_face_landmarks[0]

    xs = [lm.x for lm in face.landmark]
    ys = [lm.y for lm in face.landmark]

    min_x, max_x = min(xs), max(xs)
    min_y, max_y = min(ys), max(ys)

    bw = max_x - min_x
    bh = max_y - min_y

    # ëˆˆ ìœ„ì¹˜
    eye_ids = [33, 133, 362, 263]
    eye_ys = [face.landmark[i].y for i in eye_ids]
    avg_eye_y = sum(eye_ys) / len(eye_ys)

    # -------------------------------
    # 1) ğŸ”¥ â€œì§„ì§œ ê°€ê¹Œì›€â€ (visible_ratio ë¬´ì‹œ)
    # -------------------------------
    # bw, bhëŠ” 0~1 ë²”ìœ„ì—ì„œ ì–¼êµ´ì´ ì°¨ì§€í•˜ëŠ” ë¹„ìœ¨.
    # 0.70 ì´ìƒì´ë©´ í™”ë©´ì— ê±°ì˜ ì–¼êµ´ë§Œ ê½‰ ì°¬ ìƒíƒœ.
    if bw > 0.70 or bh > 0.70:
        return "ì¡°ê¸ˆ ë’¤ë¡œ ë¬¼ëŸ¬ë‚˜ì„¸ìš”", "move_back", False

    # -------------------------------
    # 2) ì–¼êµ´ ë³´ì´ëŠ” ë¹„ìœ¨ ê³„ì‚°
    # -------------------------------
    vis_x0 = np.clip(min_x, 0, 1)
    vis_x1 = np.clip(max_x, 0, 1)
    vis_y0 = np.clip(min_y, 0, 1)
    vis_y1 = np.clip(max_y, 0, 1)

    vis_w = (vis_x1 - vis_x0) / bw if bw > 0 else 0
    vis_h = (vis_y1 - vis_y0) / bh if bh > 0 else 0
    visible_ratio = min(vis_w, vis_h)

    # -------------------------------
    # 3) ì ˆë°˜ ì´ìƒ í”„ë ˆì„ ë°– â†’ come_in
    # -------------------------------
    if visible_ratio < 0.5:
        return "í™”ë©´ ì•ˆìœ¼ë¡œ ë“¤ì–´ì˜¤ì„¸ìš”", "come_in", False

    # -------------------------------
    # 4) ëˆˆ ìœ„ì¹˜ê°€ ë„ˆë¬´ ìœ„ â†’ come_in
    # -------------------------------
    if avg_eye_y < 0.15:
        return "í™”ë©´ ì•ˆìœ¼ë¡œ ë“¤ì–´ì˜¤ì„¸ìš”", "come_in", False

    # -------------------------------
    # 5) ì •ìƒ
    # -------------------------------
    return "ì™„ë²½í•©ë‹ˆë‹¤!", "perfect", True



# ==========================
# 4. ë©”ì¸ ë£¨í”„ (íˆìŠ¤í…Œë¦¬ì‹œìŠ¤ ì•ˆì •í™” ì ìš©)
# ==========================

# ğŸ”¥ ìƒíƒœ ì•ˆì •í™”ìš© ë³€ìˆ˜
stable_msg = None
candidate_msg = None
candidate_count = 0
REQUIRED_FRAMES = 12   # 12í”„ë ˆì„ ì—°ì† ìœ ì§€ ì‹œ ìƒíƒœ í™•ì • (30fpsâ‰ˆ0.4ì´ˆ)

def main():
    global stable_msg, candidate_msg, candidate_count

    cap = cv2.VideoCapture(0)

    if not cap.isOpened():
        print("âŒ ì›¹ìº  ì—´ê¸° ì‹¤íŒ¨")
        return

    print("ğŸ˜Š ì›¹ìº  ì‹œì‘! ì¢…ë£Œ í‚¤: 'q'")

    start_time = time.time()
    WARMUP_SECONDS = 1.5

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break

            frame = cv2.flip(frame, 1)
            h, w, _ = frame.shape

            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = face_mesh.process(rgb)

            # ì–¼êµ´ ë¶„ì„
            if results.multi_face_landmarks:
                msg, guide_state, good = analyze_faces(results.multi_face_landmarks, w, h)
            else:
                msg, guide_state, good = "í™”ë©´ ì•ˆìœ¼ë¡œ ë“¤ì–´ì˜¤ì„¸ìš”", "come_in", False

            # ==================================================
            # ğŸ”¥ ìƒíƒœ íˆìŠ¤í…Œë¦¬ì‹œìŠ¤ (í”„ë ˆì„ ê¸°ë°˜ ì•ˆì •í™”)
            # ==================================================
            if candidate_msg != msg:
                candidate_msg = msg
                candidate_count = 1
            else:
                candidate_count += 1

            # ì¼ì • í”„ë ˆì„ ìœ ì§€í•´ì•¼ ìƒíƒœ í™•ì •
            if candidate_count >= REQUIRED_FRAMES:
                stable_msg = candidate_msg

            # ìë§‰ì€ ì•ˆì •í™”ëœ stable_msgë¡œ í‘œì‹œ
            final_msg = stable_msg if stable_msg is not None else msg

            # ìë§‰ ì¶œë ¥
            draw_text(frame, final_msg, is_good=good)

            # ìŒì„± ì¬ìƒ (WARMUP í›„)
            if time.time() - start_time > WARMUP_SECONDS:
                if guide_state != "perfect":
                    play_guide(guide_state)

            # í™”ë©´ í‘œì‹œ
            cv2.imshow("Face Guide", frame)

            # ì¢…ë£Œ í‚¤ ì²˜ë¦¬
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q') or key == 27:
                break

    finally:
        cap.release()
        cv2.destroyAllWindows()
        pygame.mixer.quit()



if __name__ == "__main__":
    main()
